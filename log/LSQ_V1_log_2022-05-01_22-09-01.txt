ResNet(
  (conv1): QuantConv2d(
    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
    (activation_quantizer): LSQActivationQuantizer()
    (weight_quantizer): LSQWeightQuantizer()
  )
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): QuantConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): QuantConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): QuantConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): QuantConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): QuantConv2d(
        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): QuantConv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): QuantConv2d(
          64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (activation_quantizer): LSQActivationQuantizer()
          (weight_quantizer): LSQWeightQuantizer()
        )
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): QuantConv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): QuantConv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): QuantConv2d(
        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): QuantConv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): QuantConv2d(
          128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (activation_quantizer): LSQActivationQuantizer()
          (weight_quantizer): LSQWeightQuantizer()
        )
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): QuantConv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): QuantConv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): QuantConv2d(
        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): QuantConv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): QuantConv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (activation_quantizer): LSQActivationQuantizer()
          (weight_quantizer): LSQWeightQuantizer()
        )
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): QuantConv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): QuantConv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_quantizer): LSQActivationQuantizer()
        (weight_quantizer): LSQWeightQuantizer()
      )
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (poolavg): AvgPool2d(kernel_size=4, stride=4, padding=0)
  (fc): QuantLinear(
    in_features=512, out_features=10, bias=True
    (activation_quantizer): LSQActivationQuantizer()
    (weight_quantizer): LSQWeightQuantizer()
  )
)
Using cpu device
Epoch 0/112
